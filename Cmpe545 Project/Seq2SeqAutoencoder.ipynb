{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliye\\Anaconda3\\envs\\Audeep\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, LSTM, RepeatVector,GRU\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score,recall_score,confusion_matrix,precision_score,f1_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(Y,predictions):\n",
    "    acc=accuracy_score(Y,predictions)\n",
    "    war=recall_score(Y,predictions,average=\"weighted\")\n",
    "    wap=precision_score(Y,predictions,average=\"weighted\")\n",
    "    waf1=f1_score(Y,predictions,average=\"weighted\")\n",
    "    print(\"Accuracy: \",acc)\n",
    "    print(\"Recall: \",war)\n",
    "    print(\"Precision: \",wap)\n",
    "    print(\"F1-Score: \",waf1)\n",
    "    a=confusion_matrix(Y,predictions)\n",
    "    print(\"{0:.2f}\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\".format(acc*100,war*100,wap*100,waf1*100))\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN =True\n",
    "SAVE_FEATURES=True\n",
    "CELL_TYPE=\"gru\"\n",
    "timesteps=256\n",
    "latent_dim=256\n",
    "window_length=\"0.16\"\n",
    "window_overlap=\"0.08\"\n",
    "def save_features(file_names,X,Y,csv_file):\n",
    "    df=pd.DataFrame(X)\n",
    "    df[\"files\"]=file_names\n",
    "    df[\"Class\"]=Y\n",
    "    df.to_csv(\"features/\"+csv_file+\".csv\",index=False)\n",
    "    \n",
    "def extract_features(db):\n",
    "    train_db=pd.read_csv(\"spectograms/MeanNormalized/heartbeat-\"+window_length+\"-\"+window_overlap+\"-128-\"+db+\".csv/train/heartbeat-\"+window_length+\"-\"+window_overlap+\"-128-\"+db+\".csv\")\n",
    "    val_db=pd.read_csv(\"spectograms/MeanNormalized/heartbeat-\"+window_length+\"-\"+window_overlap+\"-128-\"+db+\".csv/devel/heartbeat-\"+window_length+\"-\"+window_overlap+\"-128-\"+db+\".csv\")\n",
    "    class0=train_db[train_db[\"label_nominal\"]==0]\n",
    "    class1=train_db[train_db[\"label_nominal\"]==1]\n",
    "    class2=train_db[train_db[\"label_nominal\"]==2]\n",
    "    \n",
    "    train_upsampled=pd.concat((class0,class0,class0,class1,class2,class2))\n",
    "    train_upsampled=train_upsampled.reindex()\n",
    "    train_Y=train_upsampled.label_nominal\n",
    "    val_Y=val_db.label_nominal\n",
    "    train_X=train_upsampled.iloc[:,4:]\n",
    "    val_X=val_db.iloc[:,4:]\n",
    "    print(len(train_X.columns))\n",
    "\n",
    "\n",
    "    \n",
    "    train_X=train_X.values.flatten().reshape(len(train_X),timesteps,187) #502,64,372\n",
    "    input_dim=train_X.shape[2]\n",
    "    \n",
    "    inputs = Input(shape=(timesteps, input_dim))\n",
    "    encoded = GRU(latent_dim)(inputs)\n",
    "\n",
    "    decoded = RepeatVector(timesteps)(encoded)\n",
    "    decoded = GRU(input_dim, return_sequences=True)(decoded)\n",
    "\n",
    "    sequence_autoencoder = Model(inputs, decoded)\n",
    "    \n",
    "    encoder = Model(inputs, encoded) #hidden representations \n",
    "    if TRAIN:\n",
    "\n",
    "\n",
    "        sequence_autoencoder.compile(optimizer='adam', loss='mse')\n",
    "        early_stop = EarlyStopping(monitor='loss', patience=3, verbose=1)\n",
    "        sequence_autoencoder.fit(train_X,train_X,batch_size=32,epochs=50,callbacks=[early_stop])\n",
    "        sequence_autoencoder.save(\"models/upsample/\"+CELL_TYPE+\"/\"+str(window_length)+\"_\"+str(window_overlap)+\"/autoencoder_2layer_\"+str(timesteps)+\"_\"+db+\"_\"+str(latent_dim)+\".model\")\n",
    "\n",
    "    else :\n",
    "        sequence_autoencoder=load_model(\"models/upsample/\"+CELL_TYPE+\"/\"+str(window_length)+\"_\"+str(window_overlap)+\"/autoencoder_2layer_\"+str(timesteps)+\"_\"+db+\"_\"+str(latent_dim)+\".model\")\n",
    "    features_train_X=encoder.predict(train_X)\n",
    "    features_val_X=encoder.predict(val_X.values.reshape(len(val_X),timesteps,187))\n",
    "    if SAVE_FEATURES:\n",
    "        save_features(train_upsampled.filename.values,features_train_X,train_Y.values,CELL_TYPE+\"/\"+str(window_length)+\"_\"+str(window_overlap)+\"/upsample_2layer_\"+str(timesteps)+\"_\"+db+\"_\"+str(latent_dim)+\"train\")\n",
    "        save_features(val_db.filename.values,features_val_X,val_Y.values,CELL_TYPE+\"/\"+str(window_length)+\"_\"+str(window_overlap)+\"/upsample_2layer_\"+str(timesteps)+\"_\"+db+\"_\"+str(latent_dim)+\"val\")\n",
    "    return features_train_X,features_val_X,train_Y,val_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47872\n",
      "Epoch 1/50\n",
      "812/812 [==============================] - 22s 27ms/step - loss: 0.1469\n",
      "Epoch 2/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0530\n",
      "Epoch 3/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0519\n",
      "Epoch 4/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0509\n",
      "Epoch 5/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0502\n",
      "Epoch 6/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0496\n",
      "Epoch 7/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0491\n",
      "Epoch 8/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0487\n",
      "Epoch 9/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0485\n",
      "Epoch 10/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0483\n",
      "Epoch 11/50\n",
      "812/812 [==============================] - 17s 22ms/step - loss: 0.0482\n",
      "Epoch 12/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0481\n",
      "Epoch 13/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0480\n",
      "Epoch 14/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0482\n",
      "Epoch 15/50\n",
      "812/812 [==============================] - 18s 22ms/step - loss: 0.0482\n",
      "Epoch 16/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0482\n",
      "Epoch 00016: early stopping\n",
      "47872\n",
      "Epoch 1/50\n",
      "812/812 [==============================] - 22s 27ms/step - loss: 0.1639\n",
      "Epoch 2/50\n",
      "812/812 [==============================] - 17s 20ms/step - loss: 0.1019\n",
      "Epoch 3/50\n",
      "812/812 [==============================] - 16s 19ms/step - loss: 0.0983\n",
      "Epoch 4/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0968\n",
      "Epoch 5/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0961\n",
      "Epoch 6/50\n",
      "812/812 [==============================] - 17s 20ms/step - loss: 0.0957\n",
      "Epoch 7/50\n",
      "812/812 [==============================] - 17s 20ms/step - loss: 0.0955\n",
      "Epoch 8/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0953\n",
      "Epoch 9/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0953\n",
      "Epoch 10/50\n",
      "812/812 [==============================] - 17s 20ms/step - loss: 0.0953\n",
      "Epoch 11/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0951\n",
      "Epoch 12/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0951\n",
      "Epoch 13/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0951\n",
      "Epoch 14/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0950\n",
      "Epoch 15/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0949\n",
      "Epoch 16/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0949\n",
      "Epoch 17/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0949\n",
      "Epoch 18/50\n",
      "812/812 [==============================] - 16s 19ms/step - loss: 0.0949\n",
      "Epoch 19/50\n",
      "812/812 [==============================] - 16s 19ms/step - loss: 0.0948\n",
      "Epoch 20/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0948\n",
      "Epoch 21/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0949\n",
      "Epoch 22/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0948\n",
      "Epoch 00022: early stopping\n",
      "47872\n",
      "Epoch 1/50\n",
      "812/812 [==============================] - 23s 28ms/step - loss: 0.0733\n",
      "Epoch 2/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0625\n",
      "Epoch 3/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0616\n",
      "Epoch 4/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0612\n",
      "Epoch 5/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0609\n",
      "Epoch 6/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0607\n",
      "Epoch 7/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0609\n",
      "Epoch 8/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0604\n",
      "Epoch 9/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0601\n",
      "Epoch 10/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0597\n",
      "Epoch 11/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0595\n",
      "Epoch 12/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0596\n",
      "Epoch 13/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0594\n",
      "Epoch 14/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0595\n",
      "Epoch 15/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0593\n",
      "Epoch 16/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0593\n",
      "Epoch 17/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0591\n",
      "Epoch 18/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0591\n",
      "Epoch 19/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0591\n",
      "Epoch 20/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0590\n",
      "Epoch 21/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0590\n",
      "Epoch 22/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0591\n",
      "Epoch 23/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0591\n",
      "Epoch 24/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0590\n",
      "Epoch 25/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0589\n",
      "Epoch 26/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0589\n",
      "Epoch 27/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0589\n",
      "Epoch 28/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0589\n",
      "Epoch 29/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0589\n",
      "Epoch 30/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0589\n",
      "Epoch 31/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0589\n",
      "Epoch 00031: early stopping\n",
      "47872\n",
      "Epoch 1/50\n",
      "812/812 [==============================] - 22s 27ms/step - loss: 0.0611\n",
      "Epoch 2/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0561\n",
      "Epoch 3/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0554\n",
      "Epoch 4/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0555\n",
      "Epoch 5/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0547\n",
      "Epoch 6/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0544\n",
      "Epoch 7/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0545\n",
      "Epoch 8/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0542\n",
      "Epoch 9/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0544\n",
      "Epoch 10/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0541\n",
      "Epoch 11/50\n",
      "812/812 [==============================] - 16s 19ms/step - loss: 0.0537\n",
      "Epoch 12/50\n",
      "812/812 [==============================] - 16s 19ms/step - loss: 0.0537\n",
      "Epoch 13/50\n",
      "812/812 [==============================] - 16s 19ms/step - loss: 0.0537\n",
      "Epoch 14/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0535\n",
      "Epoch 15/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0535\n",
      "Epoch 16/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0535\n",
      "Epoch 17/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0534\n",
      "Epoch 18/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0534\n",
      "Epoch 19/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0533\n",
      "Epoch 20/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0533\n",
      "Epoch 21/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0533\n",
      "Epoch 22/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0532\n",
      "Epoch 23/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0532\n",
      "Epoch 24/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0532\n",
      "Epoch 25/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0532\n",
      "Epoch 26/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0531\n",
      "Epoch 27/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0531\n",
      "Epoch 28/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0531\n",
      "Epoch 29/50\n",
      "812/812 [==============================] - 19s 23ms/step - loss: 0.0531\n",
      "Epoch 30/50\n",
      "812/812 [==============================] - 18s 22ms/step - loss: 0.0531\n",
      "Epoch 31/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0531\n",
      "Epoch 32/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0531\n",
      "Epoch 33/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0531\n",
      "Epoch 34/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0531\n",
      "Epoch 35/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0531\n",
      "Epoch 00035: early stopping\n",
      "47872\n",
      "Epoch 1/50\n",
      "812/812 [==============================] - 24s 29ms/step - loss: 0.0565\n",
      "Epoch 2/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0530\n",
      "Epoch 3/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0518\n",
      "Epoch 4/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0521\n",
      "Epoch 5/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0519\n",
      "Epoch 6/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0512\n",
      "Epoch 7/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0510\n",
      "Epoch 8/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0509\n",
      "Epoch 9/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0508\n",
      "Epoch 10/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0506\n",
      "Epoch 11/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0505\n",
      "Epoch 12/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0503\n",
      "Epoch 13/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0503\n",
      "Epoch 14/50\n",
      "812/812 [==============================] - 18s 22ms/step - loss: 0.0503\n",
      "Epoch 15/50\n",
      "812/812 [==============================] - 18s 22ms/step - loss: 0.0502\n",
      "Epoch 16/50\n",
      "812/812 [==============================] - 21s 26ms/step - loss: 0.0502\n",
      "Epoch 17/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0502\n",
      "Epoch 18/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0502\n",
      "Epoch 19/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0501\n",
      "Epoch 20/50\n",
      "812/812 [==============================] - 17s 20ms/step - loss: 0.0503\n",
      "Epoch 21/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0502\n",
      "Epoch 22/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0502\n",
      "Epoch 00022: early stopping\n",
      "47872\n",
      "Epoch 1/50\n",
      "812/812 [==============================] - 22s 27ms/step - loss: 0.0541\n",
      "Epoch 2/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0517\n",
      "Epoch 3/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0506\n",
      "Epoch 4/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0502\n",
      "Epoch 5/50\n",
      "812/812 [==============================] - 16s 19ms/step - loss: 0.0500\n",
      "Epoch 6/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0499\n",
      "Epoch 7/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0497\n",
      "Epoch 8/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0494\n",
      "Epoch 9/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0494\n",
      "Epoch 10/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0492\n",
      "Epoch 11/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0491\n",
      "Epoch 12/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0489\n",
      "Epoch 13/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0489\n",
      "Epoch 14/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0490\n",
      "Epoch 15/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0489\n",
      "Epoch 16/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0490\n",
      "Epoch 00016: early stopping\n",
      "47872\n",
      "Epoch 1/50\n",
      "812/812 [==============================] - 23s 29ms/step - loss: 0.0534\n",
      "Epoch 2/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0502\n",
      "Epoch 3/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0498\n",
      "Epoch 4/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0498\n",
      "Epoch 5/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0493\n",
      "Epoch 6/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0491\n",
      "Epoch 7/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0488\n",
      "Epoch 8/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0488\n",
      "Epoch 9/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0487\n",
      "Epoch 10/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0494\n",
      "Epoch 11/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0486\n",
      "Epoch 12/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0486\n",
      "Epoch 13/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0485\n",
      "Epoch 14/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0484\n",
      "Epoch 15/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0483\n",
      "Epoch 16/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0483\n",
      "Epoch 17/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0483\n",
      "Epoch 18/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0482\n",
      "Epoch 19/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0482\n",
      "Epoch 20/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0482\n",
      "Epoch 21/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0483\n",
      "Epoch 22/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0482\n",
      "Epoch 23/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0481\n",
      "Epoch 24/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0481\n",
      "Epoch 25/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0481\n",
      "Epoch 26/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0485\n",
      "Epoch 27/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0482\n",
      "Epoch 00027: early stopping\n",
      "47872\n",
      "Epoch 1/50\n",
      "812/812 [==============================] - 22s 27ms/step - loss: 0.0532\n",
      "Epoch 2/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0505\n",
      "Epoch 3/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0496\n",
      "Epoch 4/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0492\n",
      "Epoch 5/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0492\n",
      "Epoch 6/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0489\n",
      "Epoch 7/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0488\n",
      "Epoch 8/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0485\n",
      "Epoch 9/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0484\n",
      "Epoch 10/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0489\n",
      "Epoch 11/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0485\n",
      "Epoch 12/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0484\n",
      "Epoch 13/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0482\n",
      "Epoch 14/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0482\n",
      "Epoch 15/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0482\n",
      "Epoch 16/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0481\n",
      "Epoch 17/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0481\n",
      "Epoch 18/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0480\n",
      "Epoch 19/50\n",
      "812/812 [==============================] - 17s 20ms/step - loss: 0.0480\n",
      "Epoch 20/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0480\n",
      "Epoch 21/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0480\n",
      "Epoch 22/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0480\n",
      "Epoch 23/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0479\n",
      "Epoch 24/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0479\n",
      "Epoch 25/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0479\n",
      "Epoch 26/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0479\n",
      "Epoch 27/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0479\n",
      "Epoch 28/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0479\n",
      "Epoch 29/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0479\n",
      "Epoch 00029: early stopping\n",
      "47872\n",
      "Epoch 1/50\n",
      "812/812 [==============================] - 23s 28ms/step - loss: 0.0530\n",
      "Epoch 2/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0503\n",
      "Epoch 3/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0494\n",
      "Epoch 4/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0490\n",
      "Epoch 5/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0492\n",
      "Epoch 6/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0493\n",
      "Epoch 7/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0487\n",
      "Epoch 8/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0487\n",
      "Epoch 9/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0485\n",
      "Epoch 10/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0484\n",
      "Epoch 11/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0482\n",
      "Epoch 12/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0482\n",
      "Epoch 13/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0482\n",
      "Epoch 14/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0482\n",
      "Epoch 15/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0482\n",
      "Epoch 16/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0480\n",
      "Epoch 17/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0480\n",
      "Epoch 18/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0480\n",
      "Epoch 19/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0479\n",
      "Epoch 20/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0480\n",
      "Epoch 21/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0479\n",
      "Epoch 22/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0479\n",
      "Epoch 23/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0479\n",
      "Epoch 24/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0479\n",
      "Epoch 25/50\n",
      "812/812 [==============================] - 17s 20ms/step - loss: 0.0479\n",
      "Epoch 26/50\n",
      "812/812 [==============================] - 17s 21ms/step - loss: 0.0478\n",
      "Epoch 27/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0478\n",
      "Epoch 28/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0478\n",
      "Epoch 29/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0478\n",
      "Epoch 30/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0478\n",
      "Epoch 31/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0478\n",
      "Epoch 32/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0479\n",
      "Epoch 33/50\n",
      "812/812 [==============================] - 16s 20ms/step - loss: 0.0478\n",
      "Epoch 00033: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# all Y's are same\n",
    "train_30_X,val_30_X,train_30_Y,val_30_Y=extract_features(\"30\")\n",
    "train_45_X,val_45_X,train_45_Y,val_45_Y=extract_features(\"45\")\n",
    "train_65_X,val_65_X,train_65_Y,val_65_Y=extract_features(\"65\")\n",
    "train_70_X,val_70_X,train_70_Y,val_70_Y=extract_features(\"70\")\n",
    "train_75_X,val_75_X,train_75_Y,val_75_Y=extract_features(\"75\")\n",
    "train_80_X,val_80_X,train_80_Y,val_80_Y=extract_features(\"80\")\n",
    "train_85_X,val_85_X,train_85_Y,val_85_Y=extract_features(\"85\")\n",
    "train_90_X,val_90_X,train_90_Y,val_90_Y=extract_features(\"90\")\n",
    "train_95_X,val_95_X,train_95_Y,val_95_Y=extract_features(\"95\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "47872/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_X=np.concatenate((train_30_X,train_45_X,train_60_X,train_70_X,train_75_X,train_80_X,train_85_X,train_90_X,train_95_X),axis=1)\n",
    "val_X=np.concatenate((val_30_X,val_45_X,val_60_X,val_70_X,val_75_X,val_80_X,val_85_X,val_90_X,val_95_X),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(812, 2176)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 812 samples, validate on 180 samples\n",
      "Epoch 1/50\n",
      "812/812 [==============================] - 8s 10ms/step - loss: 9.6517 - acc: 0.3436 - val_loss: 11.6408 - val_acc: 0.5444\n",
      "Epoch 2/50\n",
      "812/812 [==============================] - 1s 1ms/step - loss: 10.4807 - acc: 0.3399 - val_loss: 11.6408 - val_acc: 0.5444\n",
      "Epoch 3/50\n",
      "812/812 [==============================] - 1s 1ms/step - loss: 10.4807 - acc: 0.3399 - val_loss: 11.6408 - val_acc: 0.5444\n",
      "Epoch 00003: early stopping\n",
      "Accuracy:  0.5444444444444444\n",
      "Recall:  0.5444444444444444\n",
      "Precision:  0.29641975308641977\n",
      "F1-Score:  0.3838529176658673\n",
      "54.44\t54.44\t29.64\t38.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliye\\Anaconda3\\envs\\Audeep\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\aliye\\Anaconda3\\envs\\Audeep\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0, 32,  0],\n",
       "       [ 0, 98,  0],\n",
       "       [ 0, 50,  0]], dtype=int64)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=train_X.shape[1],activation=\"relu\"))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "train_Y=to_categorical(train_75_Y)\n",
    "val_Y=to_categorical(val_30_Y)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "model.fit(train_X,train_Y,batch_size=8,epochs=50,validation_data=(val_X, val_Y),callbacks=[early_stop])\n",
    "\n",
    "predictions=np.argmax(model.predict(val_X),axis=1)\n",
    "print_metrics(val_30_Y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 812 samples, validate on 180 samples\n",
      "Epoch 1/50\n",
      "812/812 [==============================] - 4s 5ms/step - loss: 6.2330 - acc: 0.3227 - val_loss: 4.4772 - val_acc: 0.1778\n",
      "Epoch 2/50\n",
      "812/812 [==============================] - 0s 564us/step - loss: 5.6374 - acc: 0.3103 - val_loss: 4.4772 - val_acc: 0.1778\n",
      "Epoch 3/50\n",
      "812/812 [==============================] - 0s 562us/step - loss: 5.6374 - acc: 0.3103 - val_loss: 4.4772 - val_acc: 0.1778\n",
      "Epoch 00003: early stopping\n",
      "Accuracy:  0.17777777777777778\n",
      "Recall:  0.17777777777777778\n",
      "Precision:  0.03160493827160494\n",
      "F1-Score:  0.053668763102725364\n",
      "17.78\t17.78\t3.16\t5.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliye\\Anaconda3\\envs\\Audeep\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\aliye\\Anaconda3\\envs\\Audeep\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32,  0,  0],\n",
       "       [98,  0,  0],\n",
       "       [50,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=latent_dim,activation=\"relu\"))\n",
    "model.add(Dense(32, input_dim=latent_dim,activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "train_Y=to_categorical(train_75_Y)\n",
    "val_Y=to_categorical(val_75_Y)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "model.fit(train_75_X,train_Y,batch_size=8,epochs=50,validation_data=(val_75_X, val_Y),callbacks=[early_stop])\n",
    "\n",
    "predictions=np.argmax(model.predict(val_75_X),axis=1)\n",
    "print_metrics(val_30_Y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.17777777777777778\n",
      "Recall:  0.17777777777777778\n",
      "Precision:  0.03160493827160494\n",
      "F1-Score:  0.053668763102725364\n",
      "17.78\t17.78\t3.16\t5.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliye\\Anaconda3\\envs\\Audeep\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\aliye\\Anaconda3\\envs\\Audeep\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32,  0,  0],\n",
       "       [98,  0,  0],\n",
       "       [50,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_metrics(val_30_Y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(812, 128)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_60_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4444444444444444\n",
      "Recall:  0.4444444444444444\n",
      "Precision:  0.4537804655731678\n",
      "F1-Score:  0.4474149180774927\n",
      "44.44\t44.44\t45.38\t44.74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9, 13, 10],\n",
       "       [12, 53, 33],\n",
       "       [ 5, 27, 18]], dtype=int64)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svm_model=SVC(C=50,kernel=\"rbf\")\n",
    "svm_model.fit(train_X,train_30_Y)\n",
    "predictions=svm_model.predict(val_X)\n",
    "accuracy_score\n",
    "print_metrics(val_30_Y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4166666666666667\n",
      "Recall:  0.4166666666666667\n",
      "Precision:  0.44770834931439557\n",
      "F1-Score:  0.42476507713412953\n",
      "41.67\t41.67\t44.77\t42.48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7, 13, 12],\n",
       "       [13, 46, 39],\n",
       "       [ 9, 19, 22]], dtype=int64)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svm_model=SVC(C=10,kernel=\"linear\")\n",
    "svm_model.fit(train_85_X,train_75_Y)\n",
    "predictions=svm_model.predict(val_85_X)\n",
    "accuracy_score\n",
    "print_metrics(val_30_Y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fd407d6b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_30_Y.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
